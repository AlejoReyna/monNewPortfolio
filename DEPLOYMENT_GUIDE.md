# üöÄ INSTRUCCIONES DE DEPLOYMENT

## PASO 1: PREPARAR ARCHIVOS

Todos los archivos ya est√°n creados en tu proyecto. Verifica que tengas:

```
monNewPortfolio/
‚îú‚îÄ‚îÄ ollama-render/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ start.sh
‚îÇ   ‚îú‚îÄ‚îÄ health-check.sh
‚îÇ   ‚îî‚îÄ‚îÄ render.yaml
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chat/
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ route.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ page.tsx
‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ hero-chat.tsx
‚îÇ   ‚îî‚îÄ‚îÄ hooks/
‚îÇ       ‚îî‚îÄ‚îÄ useChat.ts
‚îî‚îÄ‚îÄ .env.local
```

## PASO 2: DEPLOY EN RENDER

1. **Crear cuenta en Render**: https://render.com
2. **Conectar tu repositorio de GitHub**
3. **Crear Web Service** con estos settings:
   - **Name**: `ollama-chatbot` (o el nombre que prefieras)
   - **Environment**: `Docker`
   - **Plan**: `Free`
   - **Branch**: `main` (o tu rama principal)
   - **Dockerfile path**: `./ollama-render/Dockerfile`
   - **Health Check Path**: `/api/version`
   - **Auto-Deploy**: Yes

4. **Variables de entorno en Render**:
   - `OLLAMA_HOST`: `0.0.0.0:11434`
   - `OLLAMA_KEEP_ALIVE`: `24h`

5. **Deploy**: Hacer click en "Create Web Service"

‚ö†Ô∏è **IMPORTANTE**: El primer deploy tomar√° 10-15 minutos porque descarga el modelo Llama 3.1 8B (4.7GB)

## PASO 3: CONFIGURAR VARIABLES DE ENTORNO LOCALES

1. **Actualizar .env.local** con la URL real de Render:
```bash
# Reemplaza "tu-app-ollama" con el nombre real de tu servicio
OLLAMA_URL=https://ollama-chatbot-XXXX.onrender.com
```

2. **Obtener la URL**: La encontrar√°s en el dashboard de Render despu√©s del deploy

## PASO 4: DEPLOY EN VERCEL

1. **Instalar dependencias** (si es necesario):
```bash
npm install
```

2. **Test local**:
```bash
npm run dev
```

3. **Deploy en Vercel**:
```bash
# Si tienes Vercel CLI
vercel

# O conecta tu repo en vercel.com
```

4. **Configurar variables en Vercel**:
   - Ve a tu proyecto en vercel.com
   - Settings > Environment Variables
   - Agregar: `OLLAMA_URL` = `https://tu-app-ollama.onrender.com`

## PASO 5: TESTING

### Test del backend Ollama:
```bash
curl https://tu-app-ollama.onrender.com/api/version
```

Deber√≠a responder algo como:
```json
{"version":"0.1.32"}
```

### Test del chat:
```bash
curl -X POST https://tu-vercel-app.vercel.app/api/chat \
  -H "Content-Type: application/json" \
  -d '{"messages":[{"role":"user","content":"Hola"}]}'
```

## PASO 6: TROUBLESHOOTING

### Problema: Cold starts largos
**S√≠ntoma**: El bot tarda mucho en responder la primera vez
**Soluci√≥n**: Es normal en el plan gratuito. El sistema maneja esto autom√°ticamente.

### Problema: Error 503
**S√≠ntoma**: "El servicio est√° iniciando"
**Soluci√≥n**: Esperar 30-60 segundos y volver a intentar.

### Problema: Timeout
**S√≠ntoma**: El chat no responde
**Verificar**:
1. Estado de Render: https://dashboard.render.com
2. Logs en Render
3. Variables de entorno en Vercel

### Logs √∫tiles:
- **Render**: Dashboard > Service > Logs
- **Vercel**: Dashboard > Functions > View Function Logs
- **Browser**: F12 > Console

## RESULTADO FINAL

‚úÖ **Chatbot funcionando 100% gratis**
‚úÖ **Deploy autom√°tico en Render + Vercel**  
‚úÖ **Hero component con interfaz de chat**
‚úÖ **Manejo de cold starts**
‚úÖ **Retry autom√°tico**
‚úÖ **Respuestas personalizadas de Alexis**

## COMANDOS √öTILES

```bash
# Verificar estado del servidor
curl https://tu-app-ollama.onrender.com/api/version

# Test local
npm run dev

# Build de producci√≥n
npm run build

# Ver logs de Vercel
vercel logs

# Redeploy en Render
# (Se hace autom√°ticamente al hacer push a GitHub)
```

## PERSONALIZACI√ìN ADICIONAL

### Cambiar personalidad del bot:
Edita `src/app/api/chat/route.ts` l√≠nea ~16:
```typescript
const SYSTEM_PROMPT = `Eres Alexis, un desarrollador full-stack mexicano...`
```

### Agregar m√°s sugerencias r√°pidas:
Edita `src/components/hero-chat.tsx` l√≠nea ~29:
```typescript
const quickSuggestions = [
  { en: "About me", es: "Sobre m√≠" },
  { en: "Projects", es: "Proyectos" },
  // Agregar m√°s aqu√≠
];
```

### Cambiar timeout:
Edita `src/app/api/chat/route.ts` l√≠nea ~50:
```typescript
signal: AbortSignal.timeout(30000), // 30 segundos
```

¬°Tu chatbot est√° listo! üéâ
